---
layout: post
title: "FuriosaAIのNXT RNGDサーバー発表、その真意はどこにあるのか？"
date: 2025-09-27 01:58:56 +0000
categories: ["投資分析"]
tags: ["AI", "最新ニュース", "技術動向", "投資", "チップ"]
author: "ALLFORCES編集部"
excerpt: "FuriosaAI、NXT RNGDサーバ発表について詳細に分析します。"
reading_time: 8
---

FuriosaAIのNXT RNGDサーバー発表、その真意はどこにあるのか？

いやはや、また新しいAIハードウェアのニュースが飛び込んできましたね。FuriosaAIが「NXT RNGDサーバー」を発表したと聞いて、正直なところ、私の最初の反応は「またか」というものでした。あなたも感じているかもしれませんが、この20年間、シリコンバレーから日本の片隅まで、数えきれないほどの「Nvidiaキラー」を見てきましたからね。でも、今回はちょっと立ち止まって考えてみる価値がありそうです。本当に、何かが変わる兆しなのでしょうか？

ご存知の通り、AIの進化は目覚ましく、その裏側では常にハードウェアの進化が支えてきました。特にNvidiaのGPUは、学習から推論まで、まさにAIインフラのデファクトスタンダードとして君臨しています。しかし、その圧倒的な性能と引き換えに、消費電力やコストという課題も常に付きまとってきました。データセンターの電力消費はうなぎ登りで、持続可能性という観点からも、より効率的なソリューションが求められているのは、あなたも肌で感じていることでしょう。私が初めてAIチップのスタートアップに出会ったのはもう10年以上前になりますが、その頃から「GPU以外の選択肢」を模索する動きは絶えませんでした。

さて、今回の主役であるFuriosaAIの「NXT RNGDサーバー」ですが、これは同社が開発したAI推論に特化した「RNGD（レネゲード）AIチップ」を8基搭載したエンタープライズ向けサーバーです。発表されたスペックを見ると、FP8で4ペタFLOPS、INT8で4ペタTOPSという演算能力は確かに目を引きます。さらに、合計384GBのHBM3メモリと12TB/sという驚異的なメモリ帯域幅を実現している点も、大規模言語モデル（LLM）やマルチモーダルAIシステムを扱う上で非常に重要になってきます。

しかし、私が最も注目したのは、その電力効率です。NXT RNGDサーバーの消費電力はわずか3kW。これはNvidiaのDGX H100サーバーが10kW以上を消費するのと比較すると、大幅に低い数値です。この差は、データセンターの運用コストに直結しますし、ラックあたりの密度にも大きな影響を与えます。標準的な15kWのデータセンターラックに、NXT RNGDサーバーなら最大5台を収容できるのに対し、DGX H100は1台がやっと。これは、限られたスペースと電力の中で、より多くのAI推論能力を詰め込みたい企業にとっては、非常に魅力的な提案になるはずです。LG AI Researchが、彼らの大規模言語モデル「EXAONE」にRNGDチップを採用し、GPUと比較してワットあたり2.25倍のLLM推論性能向上を報告しているという実績も、この電力効率の優位性を裏付けていますね。

FuriosaAIは2017年に韓国とシリコンバレーで設立されたスタートアップで、元AMDやSamsungのメンバーが創業に名を連ね、June Paik氏がCEOを務めています。彼らのミッションは「AIコンピューティングをより持続可能にすること」だと言いますが、今回の発表はその言葉に説得力を持たせるものだと感じました。そして、個人的に最も驚いたのは、2025年初頭にMeta Platformsからの8億ドルという巨額の買収提案を拒否し、独立路線を選んだというニュースです。これは、彼らが自社の技術と将来性に相当な自信を持っている証拠でしょう。

投資の面でも、FuriosaAIは活発です。最近完了したシリーズCブリッジファンディングラウンドで1億2,500万ドルを調達し、これまでの総資金調達額は2億4,600万ドルに達しています。企業評価額は7億3,500万ドル。韓国産業銀行、中小企業銀行、カカオインベストメント、Keistone Partners、PI Partnersといった投資家が名を連ねています。調達資金はRNGDチップの生産規模拡大と次世代チップの開発に充てられるとのこと。さらに、IPOに先立ち、シリーズDラウンドで3億ドル以上の資金調達を計画しているという話も聞こえてきます。

技術的な核心であるRNGD NPUアクセラレータチップは、テンソル収縮プロセッサ（TCP）アーキテクチャに基づいています。これは、現代の深層学習における基本的な演算であるテンソル収縮を効率的に処理するために特別に設計されたもので、GPUを使う際の非効率性を排除することを目指しているそうです。TSMCの5ナノメートル製造プロセスで製造され、SK HynixのHBM3チップを搭載している点も、最先端の技術が投入されていることを示しています。各RNGDカードは48GBのHBM3メモリを備え、FP8形式で最大512テラFLOPSの性能を提供し、熱設計電力（TDP）は約180ワット。コンピュータービジョン、LLM、マルチモーダルAIシステムといった幅広い用途に対応できるプログラマビリティも、堅牢なコンパイラによって実現されているとのこと。

では、このFuriosaAIの動きは、私たち投資家や技術者にとって何を意味するのでしょうか？ 投資家にとっては、Nvidia一強のAIハードウェア市場に風穴を開ける可能性を秘めた、新たな投資機会と映るかもしれません。特に電力効率の高さは、ESG投資の観点からも評価されるでしょう。しかし、Nvidiaの牙城は高く、ソフトウェアエコシステムの構築や、より広範な開発者コミュニティの獲得が今後の大きな課題となるはずです。

技術者や企業にとっては、AI推論の選択肢が増えることは歓迎すべきことです。オンプレミスやコロケーション環境で、より少ない電力とスペースで高性能なAI推論を実現できるNXT RNGDサーバーは、特にコストと効率を重視する企業にとって魅力的な選択肢となるでしょう。しかし、新しいアーキテクチャへの移行には、既存のモデルの最適化や、開発環境の整備といった手間も伴います。堅牢なコンパイラがあるとはいえ、実際の開発現場での使いやすさや、既存のフレームワークとの連携がどれだけスムーズに進むかが、普及の鍵を握るでしょうね。

正直なところ、私自身もまだ半信半疑な部分もあります。過去に多くの「GPUキラー」がNvidiaの分厚い壁に跳ね返されてきたのを見てきましたから。しかし、FuriosaAIがMetaからの買収提案を蹴ってまで独立路線を貫くという決断は、彼らが単なる技術的な優位性だけでなく、市場を大きく変えるという強い意志を持っていることの表れだと感じています。AIハードウェアの未来は、本当に多様化の時代へと突入するのでしょうか？ そして、この韓国発のスタートアップが、その変革の旗手となるのか、今後の動向から目が離せませんね。

AIハードウェアの未来は、本当に多様化の時代へと突入するのでしょうか？ そして、この韓国発のスタートアップが、その変革の旗手となるのか、今後の動向から目が離せませんね。

しかし、Nvidiaの牙城がなぜこれほどまでに強固なのか、その本質を改めて考えてみる必要があります。単に高性能なGPUを作っているからだけではありません。Nvidiaの最大の強みは、ハードウェアとソフトウェアが密接に統合された「CUDAエコシステム」にあると、私は見ています。開発者がGPU上でAIモデルを効率的に動かすためのライブラリ、ツール、フレームワークが膨大に揃っており、長年にわたって蓄積されてきたノウハウやコミュニティは、まさに圧倒的です。PyTorchやTensorFlowといった主要なディープラーニングフレームワークも、CUDAを前提として最適化が進んでいます。新しいAIチップが登場するたびに、「既存のCUDAコードをどれだけ簡単に移行できるか」が常に問われるのは、あなたもご存知の通りでしょう。このソフトウェアの壁は、どんなに優れたハードウェア性能を持っていても、一朝一夕には乗り越えられない大きな障壁となります。

FuriosaAIがNvidiaの支配に風穴を開けるためには、このソフトウェアエコシステムの課題にどう向き合うかが、まさに生命線となるでしょう。彼らが「堅牢なコンパイラ」を開発していると発表しているのは、この点を強く意識しているからに他なりません。既存のAIモデルをRNGDチップ上で動かす際に、開発者がほとんどコードを変更することなく、あるいは最小限の労力で最大のパフォーマンスを引き出せるか。これが実現できれば、導入のハードルはぐっと下がります。さらに、単にコンパイラを提供するだけでなく、開発者向けのドキュメント、チュートリアル、そして活発なコミュニティを構築していく地道な努力が不可欠です。オープン

---END---

オープンな開発環境とエコシステムを構築できるか、まさにそこにかかっていると言えるでしょう。

私たちが知る限り、NvidiaのCUDAは強力ですが、その閉鎖性が常に議論の的となってきました。特定のベンダーにロックインされることは、長期的な視点で見れば、企業にとってのリスクにもなり得ます。だからこそ、FuriosaAIが目指すべきは、単に「Nvidiaより速い」「Nvidiaより省電力」という性能面での優位性だけでなく、「Nvidiaと同じくらい、あるいはそれ以上に使いやすい」開発環境を提供することだと私は考えています。

彼らが言う「堅牢なコンパイラ」が、既存のPyTorchやTensorFlow、ONNXといった主要なAIフレームワークから、どれだけスムーズにRNGDチップ向けの最適化されたコードを生成できるのか。そして、その過程で開発者がどれほどの労力を必要とするのか。例えば、NvidiaのGPUに最適化されたモデルを、設定ファイルを少し変更するだけでRNGDチップ上で動かせるような、圧倒的な移行の容易さを提供できれば、それは大きなアドバンテージになります。もちろん、ただ動くだけでなく、その電力効率や性能の恩恵を最大限に引き出せるようなチューニングツールやプロファイラも不可欠です。

さらに、開発者コミュニティへの投資も忘れてはなりません。オープンソースのライブラリやツールを積極的に公開し、開発者向けのチュートリアルやドキュメントを充実させること。オンラインフォーラムや技術イベントを通じて、開発者同士が知識を共有し、協力し合える場を提供すること。これらは、Nvidiaが長年培ってきたエコシステムに真っ向から挑む上で、避けては通れない地道な努力です。正直なところ、このソフトウェアとコミュニティの構築には膨大な時間とリソースが必要であり、スタートアップにとっては非常に大きな挑戦です。しかし、Metaからの買収提案を蹴ってまで独立を選んだFuriosaAIの決意を考えると、彼らがこの課題に真剣に取り組む覚悟があるのだと信じたいですね。

**市場戦略とニッチ開拓の可能性**

FuriosaAIの戦略は、必ずしもNvidiaのあらゆる市場領域で直接対決することではないかもしれません。彼らの強みである「電力効率」と「推論性能」は、特に特定のニッチ市場で大きなアドバンテージとなり得ます。例えば、エッジAIデバイス、自動運転車、ロボティクス、あるいは電力供給に制約のあるデータセンターなどです。これらの領域では、ワットあたりの性能が、純粋なピーク性能よりも重視されるケースが多々あります。

LG AI Researchが彼らの大規模言語モデル「EXAONE」にRNGDチップを採用し、ワットあたり2.25倍のLLM推論性能向上を報告しているという事実は、この方向性が正しいことを示唆しています。大規模言語モデルの推論は、その計算量ゆえに莫大な電力を消費します。もしFuriosaAIのチップが、同等の推論結果をより少ない電力で提供できるのであれば、それはデータセンターの運用コスト削減に直結し、結果としてAIサービスの提供価格にも影響を与え、競争優位性を生み出す可能性があります。

また、彼らのミッションである「AIコンピューティングをより持続可能にすること」は、単なる美辞麗句ではありません。近年、ESG投資が注目される中で、環境負荷の低いAIソリューションは、投資家だけでなく、持続可能な経営を目指す企業にとっても魅力的な要素となります。FuriosaAIは、この持続可能性というトレンドをうまく捉え、自社の差別化要因としてアピールできるでしょう。私自身、この点がNvidiaとの差別化において、単なる性能競争とは異なる、より本質的な価値を提供し得るポイントだと感じています。

**潜在的なリスクと競争環境**

しかし、楽観視ばかりもしていられません。Nvidiaは当然、FuriosaAIのような新興勢力の台頭を座視することはないでしょう。彼らは常に新しいGPUアーキテクチャやソフトウェア機能で市場をリードし、価格戦略でも柔軟に対応してくるはずです。また、IntelのGaudiシリーズやAMDのInstinctシリーズなど、Nvidia以外の既存の大手半導体メーカーも、AIアクセラレータ市場でのシェア拡大を目指して積極的に投資を行っています。さらに、Groqのような高速推論に特化したスタートアップも存在し、競争は激化の一途を辿っています。

FuriosaAIがTSMCの5ナノメートルプロセスでチップを製造し、SK HynixのHBM3チップを搭載している点は最先端技術の証ですが、同時にサプライチェーンへの依存というリスクも抱えています。地政学的なリスクや、半導体製造能力のひっ迫は、生産規模の拡大やコストに影響を与える可能性があります。Metaからの買収提案を拒否したことは、彼らの独立性と自信の表れであると同時に、自力で資金調達を続け、市場を切り開いていくという、より困難な道を選んだことでもあります。IPOを控えているとはいえ、3億ドル以上の資金調達計画が順調に進むか、そして上場後の市場からの評価がどうなるか、今後の資金繰りも重要な要素となるでしょう。

**投資家と技術者への具体的な示唆**

では、私たち投資家や技術者は、この状況をどのように捉えるべきでしょうか？

**投資家として見れば、** FuriosaAIは、Nvidia一強の市場に風穴を開ける可能性を秘めた、ハイリスク・ハイリターンの投資機会と映るかもしれません。彼らの技術的な優位性、特に電力効率の高さと、それを裏付けるLG AI Researchの実績は魅力的です。ESG投資の観点からも、持続可能なAIコンピューティングというミッションは評価に値します。しかし、前述したように、Nvidiaの強固なエコシステムを打破する難しさ、熾烈な競争、そしてサプライチェーンや資金調達のリスクも考慮に入れる必要があります。個人的には、IPO後の株価動向や、主要な顧客獲得のニュース、そして開発者コミュニティの成長指標を注視しながら、長期的な視点で投資を検討するのが賢明だと感じています。ポートフォリオの一部として、AIハードウェア市場の多様化というトレンドに賭ける、という考え方もできるでしょう。

**技術者や企業にとって見れば、** FuriosaAIのNXT RNGDサーバーは、AI推論の選択肢を広げる上で非常に興味深い存在です。特に、データセンターの電力コスト削減や、ラックあたりの推論密度向上に課題を感じている企業にとっては、PoC（概念実証）を実施する価値は十分にあるでしょう。既存のAIモデルの移行コスト、開発者の学習曲線、そして長期的なサポート体制がどうなるかを見極めることが重要です。まずは、特定の推論ワークロードにおいて、NvidiaのGPUと比較して、本当にワットあたり、あるいはTCO（総所有コスト）で優位性があるのかを、実際に試してみることをお勧めします。堅牢なコンパイラがどれだけ「堅牢」であるか、そして既存のAIパイプラインにどれだけシームレスに組み込めるか、その実力を肌で感じる必要があるでしょう。

**AIハードウェアの未来とFuriosaAIの役割**

AIハードウェアの未来は、単一のベンダーが支配する時代から、間違いなく多様化の時代へと向かっています。学習フェーズでは依然としてNvidiaのGPUが圧倒的な存在感を示すでしょうが、推論フェーズにおいては、特定のワークロードに特化したアクセラレータや、電力効率に優れたソリューションが、より大きな役割を果たすようになるはずです。

FuriosaAIは、この多様化の波に乗る強力な候補の一つです。彼らが単なる「Nvidiaキラー」としてではなく、「Nvidiaに並ぶ、あるいは特定の領域でNvidiaを超える、新たなデファクトスタンダード」として認知される

---END---

オープンな開発環境とエコシステムを構築できるか、まさにそこにかかっていると言えるでしょう。

私たちが知る限り、NvidiaのCUDAは強力ですが、その閉鎖性が常に議論の的となってきました。特定のベンダーにロックインされることは、長期的な視点で見れば、企業にとってのリスクにもなり得ます。だからこそ、FuriosaAIが目指すべきは、単に「Nvidiaより速い」「Nvidiaより省電力」という性能面での優位性だけでなく、「Nvidiaと同じくらい、あるいはそれ以上に使いやすい」開発環境を提供することだと私は考えています。

彼らが言う「堅牢なコンパイラ」が、既存のPyTorchやTensorFlow、ONNXといった主要なAIフレームワークから、どれだけスムーズにRNGDチップ向けの最適化されたコードを生成できるのか。そして、その過程で開発者がどれほどの労力を必要とするのか。例えば、NvidiaのGPUに最適化されたモデルを、設定ファイルを少し変更するだけでRNGDチップ上で動かせるような、圧倒的な移行の容易さを提供できれば、それは大きなアドバンテージになります。もちろん、ただ動くだけでなく、その電力効率や性能の恩恵を最大限に引き出せるようなチューニングツールやプロファイラも不可欠です。

さらに、開発者コミュニティへの投資も忘れてはなりません。オープンソースのライブラリやツールを積極的に公開し、開発者向けのチュートリアルやドキュメントを充実させること。オンラインフォーラムや技術イベントを通じて、開発者同士が知識を共有し、協力し合える場を提供すること。これらは、Nvidiaが長年培ってきたエコシステムに真っ向から挑む上で、避けては通れない地道な努力です。正直なところ、このソフトウェアとコミュニティの構築には膨大な時間とリソースが必要であり、スタートアップにとっては非常に大きな挑戦です。しかし、Metaからの買収提案を蹴ってまで独立を選んだFuriosaAIの決意を考えると、彼らがこの課題に真剣に取り組む覚悟があるのだと信じたいですね。

**市場戦略とニッチ開拓の可能性**

FuriosaAIの戦略は、必ずしもNvidiaのあらゆる市場領域で直接対決することではないかもしれません。彼らの強みである「電力効率」と「推論性能」は、特に特定のニッチ市場で大きなアドバンテージとなり得ます。例えば、エッジAIデバイス、自動運転車、ロボティクス、あるいは電力供給に制約のあるデータセンターなどです。これらの領域では、ワットあたりの性能が、純粋なピーク性能よりも重視されるケースが多々あります。

LG AI Researchが彼らの大規模言語モデル「EXAONE」にRNGDチップを採用し、ワットあたり2.25倍のLLM推論性能向上を報告しているという事実は、この方向性が正しいことを示唆しています。大規模言語モデルの推論は、その計算量ゆえに莫大な電力を消費します。もしFuriosaAIのチップが、同等の推論結果をより少ない電力で提供できるのであれば、それはデータセンターの運用コスト削減に直結し、結果としてAIサービスの提供価格にも影響を与え、競争優位性を生み出す可能性があります。

また、彼らのミッションである「AIコンピューティングをより持続可能にすること」は、単なる美辞麗句ではありません。近年、ESG投資が注目される中で、環境負荷の低いAIソリューションは、投資家だけでなく、持続可能な経営を目指す企業にとっても魅力的な要素となります。FuriosaAIは、この持続可能性というトレンドをうまく捉え、自社の差別化要因としてアピールできるでしょう。私自身、この点がNvidiaとの差別化において、単なる性能競争とは異なる、より本質的な価値を提供し得るポイントだと感じています。

**潜在的なリスクと競争環境**

しかし、楽観視ばかりもしていられません。Nvidiaは当然、FuriosaAIのような新興勢力の台頭を座視することはないでしょう。彼らは常に新しいGPUアーキテクチャやソフトウェア機能で市場をリードし、価格戦略でも柔軟に対応してくるはずです。また、IntelのGaudiシリーズやAMDのInstinctシリーズなど、Nvidia以外の既存の大手半導体メーカーも、AIアクセラレータ市場でのシェア拡大を目指して積極的に投資を行っています。さらに、Groqのような高速推論に特化したスタートアップも存在し、競争は激化の一途を辿っています。

FuriosaAIがTSMCの5ナノメートルプロセスでチップを製造し、SK HynixのHBM3チップを搭載している点は最先端技術の証ですが、同時にサプライチェーンへの依存というリスクも抱えています。地政学的なリスクや、半導体製造能力のひっ迫は、生産規模の拡大やコストに影響を与える可能性があります。Metaからの買収提案を拒否したことは、彼らの独立性と自信の表れであると同時に、自力で資金調達を続け、市場を切り開いていくという、より困難な道を選んだことでもあります。IPOを控えているとはいえ、3億ドル以上の資金調達計画が順調に進むか、そして上場後の市場からの評価がどうなるか、今後の資金繰りも重要な要素となるでしょう。

**投資家と技術者への具体的な示唆**

では、私たち投資家や技術者は、この状況をどのように捉えるべきでしょうか？

**投資家として見れば、** FuriosaAIは、Nvidia一強の市場に風穴を開ける可能性を秘めた、ハイリスク・ハイリターンの投資機会と映るかもしれません。彼らの技術的な優位性、特に電力効率の高さと、それを裏付けるLG AI Researchの実績は魅力的です。ESG投資の観点からも、持続可能なAIコンピューティングというミッションは評価に値します。しかし、前述したように、Nvidiaの強固なエコシステムを打破する難しさ、熾烈な競争、そしてサプライチェーンや資金調達のリスクも考慮に入れる必要があります。個人的には、IPO後の株価動向や、主要な顧客獲得のニュース、そして開発者コミュニティの成長指標を注視しながら、長期的な視点で投資を検討するのが賢明だと感じています。ポートフォリオの一部として、AIハードウェア市場の多様化というトレンドに賭ける、という考え方もできるでしょう。

**技術者や企業にとって見れば、** FuriosaAIのNXT RNGDサーバーは、AI推論の選択肢を広げる上で非常に興味深い存在です。特に、データセンターの電力コスト削減や、ラックあたりの推論密度向上に課題を感じている企業にとっては、PoC（概念実証）を実施する価値は十分にあるでしょう。既存のAIモデルの移行コスト、開発者の学習曲線、そして長期的なサポート体制がどうなるかを見極めることが重要ですし、あなたもそう考えているかもしれません。まずは、特定の推論ワークロードにおいて、NvidiaのGPUと比較して、本当にワットあたり、あるいはTCO（総所有コスト）で優位性があるのかを、実際に試してみることをお勧めします。堅牢なコンパイラがどれだけ「堅牢」であるか、そして既存のAIパイプラインにどれだけシームレスに組み込めるか、その実力を肌で感じる必要があるでしょう。

**AIハードウェアの未来とFuriosaAIの役割**

AIハードウェアの未来は、単一のベンダーが支配する時代から、間違いなく多様化の時代へと向かっています。学習フェーズでは依然としてNvidiaのGPUが圧倒的な存在感を示すでしょうが、推論フェーズにおいては、特定のワークロードに特化したアクセラレータや、電力効率に優れたソリューションが、より大きな役割を果たすようになるはずです。

FuriosaAIは、この多様化の波に乗る強力な候補の一つです。彼らが単なる「Nvidiaキラー」としてではなく、「Nvidiaに並ぶ、あるいは特定の領域でNvidiaを超える、新たなデファクトスタンダード」として認知されるためには、単なるハードウェア性能の優位性だけでなく、開発者にとっての使いやすさ、強固なソフトウェアエコシステムの構築、そして明確な市場戦略が不可欠です。

この韓国発のスタートアップが、AIハードウェア市場の変革の旗手となり、Nvidiaの牙城に風穴を開けることができるのか。その道のりは決して平坦ではないでしょうが、彼らの技術力と、Metaからの買収提案を蹴ってまで独立路線を貫くという強い意志は、私たちに大きな期待を抱かせます。今後の動向から、本当に目が離せませんね。

---END---