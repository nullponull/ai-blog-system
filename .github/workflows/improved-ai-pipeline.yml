name: AI Article Generation & Publishing Pipeline

on:
  schedule:
    - cron: '15 */8 * * *'  # 8ÊôÇÈñì„Åî„Å®
  workflow_dispatch:

jobs:
  generate-and-publish:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          npm install -g @google/gemini-cli
          pip install transformers torch sentence-transformers scikit-learn numpy requests
          mkdir -p _temp

      - name: Generate topic list for AI industry
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          export GEMINI_API_KEY="$GEMINI_API_KEY"
          
          # Generate list of current AI topics
          gemini -m "gemini-2.5-flash" --prompt "WebSearch: AIÊ•≠Áïå ÊúÄÊñ∞„Éã„É•„Éº„Çπ „Éà„É¨„É≥„Éâ Ë©±È°å 2025„ÄÇAIÊ•≠Áïå„ÅßÊ≥®ÁõÆ„Åï„Çå„Å¶„ÅÑ„ÇãÊúÄÊñ∞„ÅÆË©±È°å„Éª„Éà„É¨„É≥„Éâ„ÇíWebÊ§úÁ¥¢„ÅßË™øÊüª„Åó„ÄÅ‰ª•‰∏ã„ÅÆÂΩ¢Âºè„Åß10ÂÄã„ÅÆÂÖ∑‰ΩìÁöÑ„Å™Ë©±È°å„Çí„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂêÑË©±È°å„ÅØ1Ë°å„Åß„ÄÅÁ∞°ÊΩî„Å´Ë°®Áèæ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ‰æã: 1. OpenAI„ÅÆÊñ∞„É¢„Éá„É´Áô∫Ë°®, 2. Google DeepMind„ÅÆÁ†îÁ©∂ÊàêÊûú, 3. ÁîüÊàêAI„ÅÆ‰ºÅÊ•≠Â∞éÂÖ•‰∫ã‰æã, 4. AIË¶èÂà∂Ê≥ïÊ°à„ÅÆÂãïÂêë, 5. Ëá™ÂãïÈÅãËª¢ÊäÄË°ì„ÅÆÈÄ≤Â±ï...ÂÆüÈöõ„ÅÆÊ§úÁ¥¢ÁµêÊûú„Å´Âü∫„Å•„ÅÑ„Å¶„ÄÅÂÖ∑‰ΩìÁöÑ„Å™‰ºÅÊ•≠Âêç„ÉªË£ΩÂìÅÂêç„Éª‰∫∫Âêç„ÇíÂê´„ÇÅ„ÅüÁèæÂÆüÁöÑ„Å™Ë©±È°å„Çí10ÂÄã„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ" > _temp/topics-list.txt
          
          echo "Generated topics list:"
          cat _temp/topics-list.txt

      - name: Generate articles for all topics
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          export GEMINI_API_KEY="$GEMINI_API_KEY"
          
          # Extract topics from the generated list - generate more articles for selection
          TOPICS=$(grep -E "^[0-9]+\." _temp/topics-list.txt | head -10)
          echo "Available topics for batch generation:"
          echo "$TOPICS"
          
          # Process all topics without duplicate checking - generate 10 articles
          TOPIC_INDEX=1
          ARTICLES_GENERATED=0
          
          echo "üìù Starting batch generation of all articles..."
          
          while IFS= read -r TOPIC_LINE; do
            if [ -z "$TOPIC_LINE" ]; then
              continue
            fi
            
            SELECTED_TOPIC=$(echo "$TOPIC_LINE" | sed 's/^[0-9]*\. *//')
            echo "üìù Generating article ${TOPIC_INDEX}: $SELECTED_TOPIC"
            
            # Determine category
            CATEGORY="ÊúÄÊñ∞ÂãïÂêë"
            if [[ "$SELECTED_TOPIC" =~ (Á†îÁ©∂|Ë´ñÊñá|Â≠¶‰ºö) ]]; then
              CATEGORY="Á†îÁ©∂Ë´ñÊñá"
            elif [[ "$SELECTED_TOPIC" =~ (ÊäÄË°ì|„Ç¢„É´„Ç¥„É™„Ç∫„É†|‰ªïÁµÑ„Åø) ]]; then
              CATEGORY="ÊäÄË°ìËß£Ë™¨"
            elif [[ "$SELECTED_TOPIC" =~ (Â∞éÂÖ•|‰∫ã‰æã|Ê¥ªÁî®) ]]; then
              CATEGORY="ÂÆüË£Ö‰∫ã‰æã"
            elif [[ "$SELECTED_TOPIC" =~ (Â∏ÇÂ†¥|ÂàÜÊûê|‰∫àÊ∏¨) ]]; then
              CATEGORY="Ê•≠ÁïåÂàÜÊûê"
            fi
            
            # Generate article
            PROMPT="WebSearch: $(date '+%YÂπ¥%mÊúà%dÊó•') $SELECTED_TOPIC„ÄÇ„Äå$SELECTED_TOPIC„Äç„Å´„Å§„ÅÑ„Å¶„ÄÅWebÊ§úÁ¥¢„ÅßÊúÄÊñ∞ÊÉÖÂ†±„ÇíË™øÊüª„Åó„ÄÅALLFORCES AIÊÉÖÂ†±„É°„Éá„Ç£„Ç¢Âêë„Åë„ÅÆÂ∞ÇÈñÄË®ò‰∫ã„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇË¶Å‰ª∂ÔºöÂÆüÈöõ„ÅÆÊúÄÊñ∞ÊÉÖÂ†±„Å´Âü∫„Å•„ÅèÂÖ∑‰ΩìÁöÑ„Å™ÂÜÖÂÆπ„ÄÅ‰ºÅÊ•≠Âêç„ÉªË£ΩÂìÅÂêç„Éª‰∫∫Âêç„ÉªÊï∞ÂÄ§„Éá„Éº„Çø„ÇíÊ≠£Á¢∫„Å´Ë®òËºâ„ÄÅÊäÄË°ìËÄÖ„ÉªÊäïË≥áÂÆ∂Âêë„Åë„ÅÆË©≥Á¥∞„Å™ÂàÜÊûê„ÄÅ3000-4000ÊñáÂ≠óÁ®ãÂ∫¶„ÄÅMarkdownÂΩ¢Âºè„ÅßÂá∫Âäõ„ÄÇÊßãÊàêÔºö# $SELECTED_TOPIC ## Ê¶ÇË¶Å„Å®ËÉåÊôØ ## Ë©≥Á¥∞„Å™ÊäÄË°ì„Éª„Éì„Ç∏„Éç„ÇπÂÜÖÂÆπ ## Â∏ÇÂ†¥„ÉªÁ´∂Âêà„Å∏„ÅÆÂΩ±Èüø ## ‰ªäÂæå„ÅÆÂ±ïÊúõ„ÄÇÂ∞ÇÈñÄÊÄß„Å®‰ø°È†ºÊÄß„ÇíÈáçË¶ñ„Åó„ÅüË®ò‰∫ã„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
            
            gemini -m "gemini-2.5-flash" --prompt "$PROMPT" > "_temp/article-${TOPIC_INDEX}.md"
            
            if [ -s "_temp/article-${TOPIC_INDEX}.md" ]; then
              # Create temporary Jekyll post for evaluation
              TITLE=$(echo "$SELECTED_TOPIC" | cut -c1-80)
              SLUG=$(echo "$SELECTED_TOPIC" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-zA-Z0-9„ÅÇ-„Çì„Ç¢-„É≥‰∏Ä-ÈæØ]/-/g' | sed 's/--*/-/g' | sed 's/^-\|-$//g' | cut -c1-50)
              FILENAME="$(date +%Y-%m-%d)-${TOPIC_INDEX}-${SLUG}.md"
              
              # Create temporary post in _temp for evaluation
              cat > "_temp/temp-${FILENAME}" << EOF
---
layout: post
title: "$TITLE"
date: $(date +%Y-%m-%d\ %H:%M:%S\ %z)
categories: ["$CATEGORY"]
tags: ["AI", "ÊúÄÊñ∞„Éã„É•„Éº„Çπ", "ÊäÄË°ìÂãïÂêë"]
author: "AIË®ò‰∫ãÁîüÊàê„Ç∑„Çπ„ÉÜ„É†"
excerpt: "AIÊ•≠Áïå„ÅÆÊúÄÊñ∞ÂãïÂêë„Å´„Å§„ÅÑ„Å¶Ë©≥„Åó„ÅèËß£Ë™¨„Åó„Åæ„Åô„ÄÇ"
reading_time: 8
topic_index: $TOPIC_INDEX
original_topic: "$SELECTED_TOPIC"
---
EOF
              
              # Add article content to temp file
              sed '1d' "_temp/article-${TOPIC_INDEX}.md" | sed '/^```markdown$/d' | sed '/^```$/d' >> "_temp/temp-${FILENAME}"
              
              echo "‚úÖ Generated temp article: temp-${FILENAME}"
              ARTICLES_GENERATED=$((ARTICLES_GENERATED + 1))
            else
              echo "‚ùå Failed to generate article for: $SELECTED_TOPIC"
            fi
            
            TOPIC_INDEX=$((TOPIC_INDEX + 1))
          done <<< "$TOPICS"
          
          echo "üìä Batch generation completed: $ARTICLES_GENERATED articles generated"

      - name: Semantic article selection and cleanup
        run: |
          echo "üß† Starting Transformer-based article selection..."
          
          # Prepare existing articles for comparison
          if ls _posts/*.md 1> /dev/null 2>&1; then
            find _posts -name "*.md" -mtime -2 -exec grep -h "^title:" {} \; 2>/dev/null | head -15 > _temp/existing_titles.txt
            echo "üìö Found existing articles for comparison:"
            head -3 _temp/existing_titles.txt
          else
            touch _temp/existing_titles.txt
            echo "üìù No existing articles found"
          fi
          
          # Create article selector script
          cat > _temp/article_selector.py << 'EOF'
import os
import json
import glob
from transformers import AutoTokenizer, AutoModel
import torch
from sklearn.metrics.pairwise import cosine_similarity

# Load Japanese BERT model
model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'
print(f"ü§ñ Loading model: {model_name}")
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

def get_embedding(text):
    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    return outputs.last_hidden_state.mean(dim=1).numpy()

def extract_title(filepath):
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            if line.startswith('title:'):
                return line.replace('title:', '').strip().strip('"')
    return ""

def calculate_quality_score(filepath):
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
        # Simple quality metrics
        word_count = len(content.split())
        has_headers = '##' in content
        has_japanese = any(ord(c) > 127 for c in content)
        
        score = 0
        if word_count > 500: score += 30
        if word_count > 1000: score += 20
        if has_headers: score += 25
        if has_japanese: score += 25
        
        return min(score, 100)

# Load existing titles
existing_titles = []
if os.path.exists('_temp/existing_titles.txt'):
    with open('_temp/existing_titles.txt', 'r') as f:
        existing_titles = [line.strip().replace('title:', '').strip().strip('"') 
                          for line in f.readlines() if line.strip()]

# Process temp articles
temp_articles = glob.glob('_temp/temp-*.md')
article_scores = []

print(f"üìä Evaluating {len(temp_articles)} generated articles...")

for filepath in temp_articles:
    title = extract_title(filepath)
    if not title:
        continue
        
    # Quality score
    quality = calculate_quality_score(filepath)
    
    # Semantic similarity with existing articles
    max_similarity = 0.0
    title_embedding = get_embedding(title)
    
    for existing_title in existing_titles:
        if existing_title:
            existing_embedding = get_embedding(existing_title)
            similarity = cosine_similarity(
                title_embedding.reshape(1, -1),
                existing_embedding.reshape(1, -1)
            )[0][0]
            max_similarity = max(max_similarity, similarity)
    
    # Determine if article should be published (not a duplicate)
    is_duplicate = max_similarity > 0.75  # Threshold for considering duplicate
    should_publish = not is_duplicate
    
    article_scores.append({
        'filepath': filepath,
        'title': title,
        'quality': quality,
        'max_similarity': max_similarity,
        'is_duplicate': is_duplicate,
        'should_publish': should_publish
    })
    
    status = "DUPLICATE" if is_duplicate else "UNIQUE"
    print(f"üìù {os.path.basename(filepath)}: quality={quality:.1f}, similarity={max_similarity:.3f} -> {status}")

# Select all non-duplicate articles for publication
selected_articles = [article for article in article_scores if article['should_publish']]
duplicate_count = len([article for article in article_scores if article['is_duplicate']])

print(f"\n‚úÖ Selected {len(selected_articles)} unique articles for publication:")
print(f"üîÑ Skipped {duplicate_count} duplicate articles")
for i, article in enumerate(selected_articles, 1):
    print(f"{i}. {article['title'][:60]}... (quality: {article['quality']:.1f})")

# Save selection results
with open('_temp/selected_articles.json', 'w', encoding='utf-8') as f:
    json.dump(selected_articles, f, ensure_ascii=False, indent=2)
    
print(f"üíæ Selection results saved to _temp/selected_articles.json")
EOF
          
          # Run article selection
          python3 _temp/article_selector.py
          
          # Move selected articles to _posts
          echo "üìÅ Moving selected articles to _posts directory..."
          SELECTED_COUNT=0
          
          if [ -f "_temp/selected_articles.json" ]; then
            python3 -c "
import json
with open('_temp/selected_articles.json', 'r') as f:
    selected = json.load(f)
for article in selected:
    print(article['filepath'])
" | while read -r temp_file; do
              if [ -f "$temp_file" ]; then
                # Extract final filename from temp file
                final_name=$(basename "$temp_file" | sed 's/^temp-//')
                cp "$temp_file" "_posts/$final_name"
                echo "‚úÖ Published: $final_name"
                SELECTED_COUNT=$((SELECTED_COUNT + 1))
              fi
            done
            
            echo "üéâ Published $SELECTED_COUNT selected articles"
          else
            echo "‚ùå No selection results found"
          fi
          
          # Clean up temp files
          echo "üßπ Cleaning up temporary files..."
          rm -f _temp/temp-*.md _temp/article-*.md

      - name: Setup Ruby and Jekyll
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: '3.1'
          bundler-cache: true

      - name: Build and Deploy
        run: |
          bundle install
          bundle exec jekyll build

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: './_site'

      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4

      - name: Commit generated articles
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          if [ -n "$(git status --porcelain _posts/)" ]; then
            ARTICLE_COUNT=$(ls _posts/$(date +%Y-%m-%d)-*.md 2>/dev/null | wc -l)
            git add _posts/
            git commit -m "ü§ñ Add $ARTICLE_COUNT AI articles - $(date +%Y-%m-%d)"
            git push
            echo "‚úÖ Committed $ARTICLE_COUNT new articles"
          else
            echo "‚ÑπÔ∏è  No new articles to commit"
          fi