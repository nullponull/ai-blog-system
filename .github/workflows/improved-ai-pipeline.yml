name: AI Article Generation & Publishing Pipeline

on:
  schedule:
    - cron: '15 */8 * * *'  # 8ÊôÇÈñì„Åî„Å®
  workflow_dispatch:

jobs:
  generate-and-publish:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          npm install -g @google/gemini-cli textlint textlint-rule-preset-japanese textlint-rule-preset-ja-technical-writing
          pip install sentence-transformers scikit-learn numpy requests pillow
          mkdir -p _temp assets/images/posts

      - name: Generate topics and articles
        shell: bash
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          export GEMINI_API_KEY="$GEMINI_API_KEY"
          
          echo "üéØ Generating AI topics..."
          echo "Debug: GEMINI_API_KEY is $([ -n "$GEMINI_API_KEY" ] && echo "set (length: ${#GEMINI_API_KEY})" || echo "NOT SET")"
          
          # GitHub ActionsÁí∞Â¢É„Åß„ÅÆAPI keyË™çË®ºÁ¢∫Ë™ç
          if [ -z "$GEMINI_API_KEY" ]; then
            echo "‚ùå GEMINI_API_KEY is not set. Please check GitHub Secrets configuration."
            exit 1
          fi
          
          # Gemini CLI with API key authentication
          echo "Testing Gemini API connection..."
          if ! gemini --version; then
            echo "‚ùå Gemini CLI not found or not working"
            exit 1
          fi
          
          # API call with detailed error reporting
          echo "üéØ Calling Gemini API..."
          PROMPT="WebSearch: AIÊ•≠Áïå ÊúÄÊñ∞„Éã„É•„Éº„Çπ „Éà„É¨„É≥„Éâ Ë©±È°å„ÄÇAIÊ•≠Áïå„ÅßÊ≥®ÁõÆ„Åï„Çå„Å¶„ÅÑ„ÇãÊúÄÊñ∞„ÅÆË©±È°å„Éª„Éà„É¨„É≥„Éâ„ÇíWebÊ§úÁ¥¢„ÅßË™øÊüª„Åó„ÄÅ‰ª•‰∏ã„ÅÆÂΩ¢Âºè„Åß10ÂÄã„ÅÆÂÖ∑‰ΩìÁöÑ„Å™Ë©±È°å„Çí„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂêÑË©±È°å„ÅØ1Ë°å„Åß„ÄÅÁ∞°ÊΩî„Å´Ë°®Áèæ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ‰æã: 1. OpenAI„ÅÆÊñ∞„É¢„Éá„É´Áô∫Ë°®, 2. Google DeepMind„ÅÆÁ†îÁ©∂ÊàêÊûú, 3. ÁîüÊàêAI„ÅÆ‰ºÅÊ•≠Â∞éÂÖ•‰∫ã‰æã, 4. AIË¶èÂà∂Ê≥ïÊ°à„ÅÆÂãïÂêë, 5. Ëá™ÂãïÈÅãËª¢ÊäÄË°ì„ÅÆÈÄ≤Â±ï...ÂÆüÈöõ„ÅÆÊ§úÁ¥¢ÁµêÊûú„Å´Âü∫„Å•„ÅÑ„Å¶„ÄÅÂÖ∑‰ΩìÁöÑ„Å™‰ºÅÊ•≠Âêç„ÉªË£ΩÂìÅÂêç„Éª‰∫∫Âêç„ÇíÂê´„ÇÅ„ÅüÁèæÂÆüÁöÑ„Å™Ë©±È°å„Çí10ÂÄã„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
          
          if gemini -m "gemini-2.5-flash" --prompt "$PROMPT" > _temp/topics.txt 2>_temp/gemini_error.log; then
            echo "‚úÖ Gemini API call successful"
          else
            echo "‚ùå Gemini API call failed"
            echo "Error log:"
            cat _temp/gemini_error.log || echo "No error log available"
            echo "Checking for common issues:"
            echo "- API Key format: $(echo "$GEMINI_API_KEY" | sed 's/.*\(.....\)$/***\1/')"
            echo "- Network connectivity test:"
            curl -s --max-time 10 https://generativelanguage.googleapis.com > /dev/null && echo "  ‚úÖ Can reach Google AI API" || echo "  ‚ùå Cannot reach Google AI API"
            exit 1
          fi
          
          echo "Generated topics:"
          head -15 _temp/topics.txt
          
          # Extract and filter duplicate topics
          ALL_GENERATED_TOPICS=$(grep -E "^[0-9]+\." _temp/topics.txt)
          echo "üìù Initial topics generated:"
          echo "$ALL_GENERATED_TOPICS"
          
          if [ -z "$ALL_GENERATED_TOPICS" ]; then
            echo "‚ùå No topics generated, exiting..."
            exit 1
          fi
          
          # Get existing titles for duplicate check (last 5 days)
          if ls _posts/*.md 1> /dev/null 2>&1; then
            find _posts -name "*.md" -mtime -5 -exec grep -h "^title:" {} \; 2>/dev/null | sed 's/^title: *["]*\|["]*$//g' > _temp/existing_titles.txt
          else
            touch _temp/existing_titles.txt
          fi
          
          echo "üîç Filtering out duplicate topics..."
          TOPICS=""
          TOPIC_COUNT=0
          RETRY_COUNT=0
          MAX_RETRIES=3
          
          # Filter duplicates and get unique topics (reduced to 5 to stay within API limits)
          while IFS= read -r topic_line && [ $TOPIC_COUNT -lt 5 ]; do
            if [ -z "$topic_line" ]; then
              continue
            fi
            
            topic_title=$(printf '%s\n' "$topic_line" | sed 's/^[0-9]*\. *//')
            echo "üîç Checking: $topic_title"
            
            # Simple keyword-based duplicate check
            is_duplicate=false
            if [ -s _temp/existing_titles.txt ]; then
              # Extract key words from topic (first 3 significant words)
              topic_keywords=$(echo "$topic_title" | sed 's/[()ÔºàÔºâ].*//g' | head -c 30)
              while IFS= read -r existing_title; do
                if [ -n "$existing_title" ] && echo "$existing_title" | grep -qi "$(echo "$topic_keywords" | cut -d' ' -f1-2)"; then
                  echo "‚è≠Ô∏è Duplicate detected: $topic_title (similar to existing: $existing_title)"
                  is_duplicate=true
                  break
                fi
              done < _temp/existing_titles.txt
            fi
            
            if [ "$is_duplicate" = false ]; then
              if [ -z "$TOPICS" ]; then
                TOPICS="$topic_line"
              else
                TOPICS="$TOPICS"$'\n'"$topic_line"
              fi
              TOPIC_COUNT=$((TOPIC_COUNT + 1))
              echo "‚úÖ Added unique topic: $topic_title"
            fi
          done <<< "$ALL_GENERATED_TOPICS"
          
          # If we don't have enough unique topics, generate more
          while [ $TOPIC_COUNT -lt 5 ] && [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "üîÑ Need more topics ($TOPIC_COUNT/5). Retry $RETRY_COUNT/$MAX_RETRIES with different prompt..."
            
            # Generate additional topics with different search strategies
            case $RETRY_COUNT in
              1)
                ADDITIONAL_PROMPT="WebSearch: AIÊ•≠Áïå „Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó ÊäïË≥á Ë≥áÈáëË™øÈÅî IPO M&A„ÄÇAIÈñ¢ÈÄ£„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„ÇÑÊäïË≥áÂãïÂêë„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„ÅüÊúÄÊñ∞Ë©±È°å„Çí$(( 5 - TOPIC_COUNT + 2 ))ÂÄãÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂÖ∑‰ΩìÁöÑ„Å™‰ºÅÊ•≠Âêç„ÉªÈáëÈ°ç„ÉªÊäïË≥áÂÆ∂Âêç„ÇíÂê´„ÇÄË©±È°å„ÇíÁï™Âè∑‰ªò„Åç„Åß„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„ÄÇ"
                ;;
              2)
                ADDITIONAL_PROMPT="WebSearch: AIÊ•≠Áïå Á†îÁ©∂ Ë´ñÊñá Â≠¶‰ºö Â§ßÂ≠¶ Á†îÁ©∂Ê©üÈñ¢„ÄÇAIÁ†îÁ©∂„ÇÑÂ≠¶Ë°ìË´ñÊñá„ÄÅÁ†îÁ©∂Ê©üÈñ¢„ÅÆÊúÄÊñ∞ÊàêÊûú„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„ÅüË©±È°å„Çí$(( 5 - TOPIC_COUNT + 2 ))ÂÄãÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂÖ∑‰ΩìÁöÑ„Å™Á†îÁ©∂ËÄÖÂêç„ÉªÂ§ßÂ≠¶Âêç„ÉªË´ñÊñáÂêç„ÇíÂê´„ÇÄË©±È°å„ÇíÁï™Âè∑‰ªò„Åç„Åß„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„ÄÇ"
                ;;
              *)
                ADDITIONAL_PROMPT="WebSearch: AIÊ•≠Áïå ÊîøÂ∫ú ÊîøÁ≠ñ Ë¶èÂà∂ Ê≥ïÂæã ÂõΩÈöõÂçîÂäõ„ÄÇAIÈñ¢ÈÄ£„ÅÆÊîøÂ∫úÊîøÁ≠ñ„ÇÑË¶èÂà∂„ÄÅÂõΩÈöõÁöÑ„Å™Âèñ„ÇäÁµÑ„Åø„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„ÅüË©±È°å„Çí$(( 5 - TOPIC_COUNT + 2 ))ÂÄãÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂÖ∑‰ΩìÁöÑ„Å™ÂõΩÂêç„ÉªÊîøÂ∫úÊ©üÈñ¢Âêç„ÉªÊîøÁ≠ñÂêç„ÇíÂê´„ÇÄË©±È°å„ÇíÁï™Âè∑‰ªò„Åç„Åß„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„ÄÇ"
                ;;
            esac
            
            if gemini -m "gemini-2.5-flash" --prompt "$ADDITIONAL_PROMPT" > _temp/additional_topics.txt 2>/dev/null; then
              ADDITIONAL_TOPICS=$(grep -E "^[0-9]+\." _temp/additional_topics.txt)
              echo "Generated additional topics:"
              echo "$ADDITIONAL_TOPICS"
              
              # Filter new topics for duplicates
              while IFS= read -r topic_line && [ $TOPIC_COUNT -lt 5 ]; do
                if [ -z "$topic_line" ]; then
                  continue
                fi
                
                topic_title=$(printf '%s\n' "$topic_line" | sed 's/^[0-9]*\. *//')
                
                # Check against existing titles and already selected topics
                is_duplicate=false
                topic_keywords=$(echo "$topic_title" | sed 's/[()ÔºàÔºâ].*//g' | head -c 30)
                
                # Check against existing posts
                if [ -s _temp/existing_titles.txt ]; then
                  while IFS= read -r existing_title; do
                    if [ -n "$existing_title" ] && echo "$existing_title" | grep -qi "$(echo "$topic_keywords" | cut -d' ' -f1-2)"; then
                      is_duplicate=true
                      break
                    fi
                  done < _temp/existing_titles.txt
                fi
                
                # Check against already selected topics
                if [ "$is_duplicate" = false ] && echo "$TOPICS" | grep -qi "$(echo "$topic_keywords" | cut -d' ' -f1-2)"; then
                  is_duplicate=true
                fi
                
                if [ "$is_duplicate" = false ]; then
                  TOPICS="$TOPICS"$'\n'"$topic_line"
                  TOPIC_COUNT=$((TOPIC_COUNT + 1))
                  echo "‚úÖ Added additional unique topic: $topic_title"
                fi
              done <<< "$ADDITIONAL_TOPICS"
            else
              echo "‚ö†Ô∏è Failed to generate additional topics"
              break
            fi
          done
          
          # Final check: if we still don't have enough topics after all retries
          if [ $TOPIC_COUNT -lt 5 ]; then
            echo "‚ö†Ô∏è Warning: Only $TOPIC_COUNT unique topics found after $MAX_RETRIES retries"
            echo "‚ö†Ô∏è This might indicate topic exhaustion or API issues"
            echo "‚ö†Ô∏è Proceeding with available topics to avoid infinite processing"
          elif [ $TOPIC_COUNT -lt 10 ]; then
            echo "‚ÑπÔ∏è Note: Found $TOPIC_COUNT topics (less than target 10)"
            echo "‚ÑπÔ∏è Proceeding with available unique topics"
          fi
          
          # Ensure we have at least some topics to process  
          if [ $TOPIC_COUNT -eq 0 ]; then
            echo "‚ùå No unique topics found after $MAX_RETRIES retries. This indicates:"
            echo "   - All generated topics were duplicates of recent articles"
            echo "   - API issues preventing topic generation"
            echo "   - Possible topic exhaustion in current search domains"
            echo "‚ùå Exiting to prevent infinite processing."
            exit 1
          elif [ $TOPIC_COUNT -lt 3 ]; then
            echo "‚ö†Ô∏è Very few unique topics ($TOPIC_COUNT) found. This may indicate topic saturation."
            echo "‚ö†Ô∏è Consider adjusting search criteria or reducing posting frequency."
          fi
          
          echo "üìä Final unique topics selected: $TOPIC_COUNT/5"
          TOPICS=$(printf '%s\n' "$TOPICS")
          echo "Final topics for processing:"
          echo "$TOPICS"
          
          # Generate articles for all topics
          TOPIC_INDEX=1
          GENERATED_COUNT=0
          
          set +e  # Continue on errors
          export LC_ALL=C  # Set locale to avoid encoding issues
          
          # „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±ËøΩÂä†
          echo "üîç Debug: Total topics found: $(echo "$TOPICS" | wc -l)"
          echo "üîç Debug: Topics content:"
          printf '%s\n' "$TOPICS" | nl
          echo "üîç Debug: Starting loop with TOPIC_INDEX=$TOPIC_INDEX, GENERATED_COUNT=$GENERATED_COUNT"
          
          # Write topics to temporary file for stable processing (fix newline handling)
          echo "$TOPICS" > _temp/topics_for_loop.txt
          echo "üîç Debug: Written $(wc -l < _temp/topics_for_loop.txt) lines to temp file"
          
          # Use file descriptor 9 to avoid subshell (Web search solution)
          exec 9< _temp/topics_for_loop.txt
          
          while IFS= read -r TOPIC_LINE <&9; do
            if [ -z "$TOPIC_LINE" ]; then
              continue
            fi
            
            echo "üîç Debug: Processing topic $TOPIC_INDEX: '$TOPIC_LINE'"
            
            # „Çà„ÇäÂÆâÂÖ®„Å™sedÂá¶ÁêÜ
            TOPIC=$(printf '%s\n' "$TOPIC_LINE" | sed 's/^[0-9]*\. *//')
            echo "üîç Debug: Extracted topic: '$TOPIC'"
            echo "üìù Generating article $TOPIC_INDEX: $TOPIC"
            
            # Category determination (caseÊñá„Å´Â§âÊõ¥)
            CATEGORY="ÊúÄÊñ∞ÂãïÂêë"
            case "$TOPIC" in
                *Á†îÁ©∂*|*Ë´ñÊñá*|*Â≠¶‰ºö*) CATEGORY="Á†îÁ©∂Ë´ñÊñá" ;;
                *ÊäÄË°ì*|*„Ç¢„É´„Ç¥„É™„Ç∫„É†*|*‰ªïÁµÑ„Åø*) CATEGORY="ÊäÄË°ìËß£Ë™¨" ;;
                *Â∞éÂÖ•*|*‰∫ã‰æã*|*Ê¥ªÁî®*) CATEGORY="ÂÆüË£Ö‰∫ã‰æã" ;;
                *Â∏ÇÂ†¥*|*ÂàÜÊûê*|*‰∫àÊ∏¨*) CATEGORY="Ê•≠ÁïåÂàÜÊûê" ;;
            esac
            
            # Generate article with timeout to prevent excessive Actions usage
            PROMPT="WebSearch: $(date '+%YÂπ¥%mÊúà%dÊó•') $TOPIC„ÄÇ„Äå$TOPIC„Äç„Å´„Å§„ÅÑ„Å¶„ÄÅWebÊ§úÁ¥¢„ÅßÊúÄÊñ∞ÊÉÖÂ†±„ÇíË™øÊüª„Åó„ÄÅALLFORCES AIÊÉÖÂ†±„É°„Éá„Ç£„Ç¢Âêë„Åë„ÅÆÂ∞ÇÈñÄË®ò‰∫ã„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇË¶Å‰ª∂ÔºöÂÆüÈöõ„ÅÆÊúÄÊñ∞ÊÉÖÂ†±„Å´Âü∫„Å•„ÅèÂÖ∑‰ΩìÁöÑ„Å™ÂÜÖÂÆπ„ÄÅ‰ºÅÊ•≠Âêç„ÉªË£ΩÂìÅÂêç„Éª‰∫∫Âêç„ÉªÊï∞ÂÄ§„Éá„Éº„Çø„ÇíÊ≠£Á¢∫„Å´Ë®òËºâ„ÄÅÊäÄË°ìËÄÖ„ÉªÊäïË≥áÂÆ∂Âêë„Åë„ÅÆË©≥Á¥∞„Å™ÂàÜÊûê„ÄÅ3000-4000ÊñáÂ≠óÁ®ãÂ∫¶„ÄÅMarkdownÂΩ¢Âºè„ÅßÂá∫Âäõ„ÄÇÊßãÊàêÔºö# $TOPIC ## Ê¶ÇË¶Å„Å®ËÉåÊôØ ## Ë©≥Á¥∞„Å™ÊäÄË°ì„Éª„Éì„Ç∏„Éç„ÇπÂÜÖÂÆπ ## Â∏ÇÂ†¥„ÉªÁ´∂Âêà„Å∏„ÅÆÂΩ±Èüø ## ‰ªäÂæå„ÅÆÂ±ïÊúõ„ÄÇÂ∞ÇÈñÄÊÄß„Å®‰ø°È†ºÊÄß„ÇíÈáçË¶ñ„Åó„ÅüË®ò‰∫ã„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
            
            # Add timeout to prevent hanging on rate limits
            if timeout 120 gemini -m "gemini-2.5-flash" --prompt "$PROMPT" > "_temp/article-${TOPIC_INDEX}.md" 2>_temp/gemini_error_${TOPIC_INDEX}.log; then
              echo "‚úÖ Article generation completed for topic $TOPIC_INDEX"
            else
              exit_code=$?
              echo "‚ùå Article generation failed for topic $TOPIC_INDEX"
              echo "Error details:"
              cat _temp/gemini_error_${TOPIC_INDEX}.log 2>/dev/null || echo "No error log available"
              
              # Check if it's a rate limit error (429)
              if grep -q "429\|RESOURCE_EXHAUSTED\|quota" _temp/gemini_error_${TOPIC_INDEX}.log 2>/dev/null; then
                echo "üö´ Rate limit reached. Stopping to avoid wasting Actions time."
                echo "üìÖ Daily quota resets at midnight Pacific Time (5PM JST in summer)"
                break
              fi
              continue
            fi
            
            if [ -s "_temp/article-${TOPIC_INDEX}.md" ]; then
              # „Çà„ÇäÂÆâÂÖ®„Å™ÊñáÂ≠óÂàóÂá¶ÁêÜ
              TITLE=$(printf '%s' "$TOPIC" | head -c 80)
              SLUG=$(printf '%s' "$TOPIC" | tr '[:upper:]' '[:lower:]' | tr -cd '[:alnum:]-' | sed 's/--*/-/g' | sed 's/^-\|-$//g' | head -c 50)
              FILENAME="$(date +%Y-%m-%d)-${TOPIC_INDEX}-${SLUG}.md"
              
              # Store in temp for processing using printf
              printf '%s\n' "---" "layout: post" "title: \"$TITLE\"" "date: $(date +%Y-%m-%d\ %H:%M:%S\ %z)" "categories: [\"$CATEGORY\"]" "tags: [\"AI\", \"ÊúÄÊñ∞„Éã„É•„Éº„Çπ\", \"ÊäÄË°ìÂãïÂêë\"]" "author: \"AIË®ò‰∫ãÁîüÊàê„Ç∑„Çπ„ÉÜ„É†\"" "excerpt: \"AIÊ•≠Áïå„ÅÆÊúÄÊñ∞ÂãïÂêë„Å´„Å§„ÅÑ„Å¶Ë©≥„Åó„ÅèËß£Ë™¨„Åó„Åæ„Åô„ÄÇ\"" "reading_time: 8" "---" > "_temp/temp-${FILENAME}"
              
              # „Çà„ÇäÂÆâÂÖ®„Å™„Éï„Ç°„Ç§„É´Âá¶ÁêÜ
              tail -n +2 "_temp/article-${TOPIC_INDEX}.md" | sed '/^```markdown$/d' | sed '/^```$/d' >> "_temp/temp-${FILENAME}"
              
              echo "‚úÖ Generated: temp-${FILENAME}"
              GENERATED_COUNT=$((GENERATED_COUNT + 1))
            else
              echo "‚ùå Failed to generate: $TOPIC"
            fi
            
            TOPIC_INDEX=$((TOPIC_INDEX + 1))
            echo "üîç Debug: Completed topic $((TOPIC_INDEX - 1)), moving to next..."
          done
          
          # Close file descriptor
          exec 9<&-
          
          echo "üîç Debug: Loop completed with TOPIC_INDEX=$TOPIC_INDEX, GENERATED_COUNT=$GENERATED_COUNT"
          set -e  # Re-enable exit on error
          echo "üìä Generated $GENERATED_COUNT articles"

      - name: Semantic article selection
        run: |
          echo "üß† Starting semantic analysis..."
          
          # Get existing titles
          if ls _posts/*.md 1> /dev/null 2>&1; then
            find _posts -name "*.md" -mtime -2 -exec grep -h "^title:" {} \; 2>/dev/null | head -15 > _temp/existing_titles.txt
          else
            touch _temp/existing_titles.txt
          fi
          
          # Create Python script for semantic analysis using echo statements
          echo "import os" > _temp/semantic_selector.py
          echo "import glob" >> _temp/semantic_selector.py
          echo "from sentence_transformers import SentenceTransformer" >> _temp/semantic_selector.py
          echo "from sklearn.metrics.pairwise import cosine_similarity" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "print('Loading multilingual sentence transformer model...')" >> _temp/semantic_selector.py
          echo "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "def get_embedding(text):" >> _temp/semantic_selector.py
          echo "    return model.encode([text])" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "def extract_title(filepath):" >> _temp/semantic_selector.py
          echo "    with open(filepath, 'r', encoding='utf-8') as f:" >> _temp/semantic_selector.py
          echo "        for line in f:" >> _temp/semantic_selector.py
          echo "            if line.startswith('title:'):" >> _temp/semantic_selector.py
          echo "                return line.replace('title:', '').strip().strip('\"')" >> _temp/semantic_selector.py
          echo "    return ''" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "existing_titles = []" >> _temp/semantic_selector.py
          echo "if os.path.exists('_temp/existing_titles.txt'):" >> _temp/semantic_selector.py
          echo "    with open('_temp/existing_titles.txt', 'r') as f:" >> _temp/semantic_selector.py
          echo "        existing_titles = [line.strip().replace('title:', '').strip().strip('\"') for line in f.readlines() if line.strip()]" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "temp_articles = glob.glob('_temp/temp-*.md')" >> _temp/semantic_selector.py
          echo "published_count = 0" >> _temp/semantic_selector.py
          echo "print(f'Evaluating {len(temp_articles)} articles...')" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "for filepath in temp_articles:" >> _temp/semantic_selector.py
          echo "    title = extract_title(filepath)" >> _temp/semantic_selector.py
          echo "    if not title:" >> _temp/semantic_selector.py
          echo "        continue" >> _temp/semantic_selector.py
          echo "    max_similarity = 0.0" >> _temp/semantic_selector.py
          echo "    if existing_titles:" >> _temp/semantic_selector.py
          echo "        title_embedding = get_embedding(title)" >> _temp/semantic_selector.py
          echo "        for existing_title in existing_titles:" >> _temp/semantic_selector.py
          echo "            if existing_title:" >> _temp/semantic_selector.py
          echo "                existing_embedding = get_embedding(existing_title)" >> _temp/semantic_selector.py
          echo "                similarity = cosine_similarity(title_embedding.reshape(1, -1), existing_embedding.reshape(1, -1))[0][0]" >> _temp/semantic_selector.py
          echo "                max_similarity = max(max_similarity, similarity)" >> _temp/semantic_selector.py
          echo "    is_duplicate = max_similarity > 0.75" >> _temp/semantic_selector.py
          echo "    if not is_duplicate:" >> _temp/semantic_selector.py
          echo "        final_name = os.path.basename(filepath).replace('temp-', '')" >> _temp/semantic_selector.py
          echo "        os.rename(filepath, f'_posts/{final_name}')" >> _temp/semantic_selector.py
          echo "        print(f'Published: {final_name}')" >> _temp/semantic_selector.py
          echo "        published_count += 1" >> _temp/semantic_selector.py
          echo "    else:" >> _temp/semantic_selector.py
          echo "        print(f'Skipped duplicate: {title[:50]}... (similarity: {max_similarity:.3f})')" >> _temp/semantic_selector.py
          echo "print(f'Published {published_count} unique articles')" >> _temp/semantic_selector.py
          
          # Run the semantic selector
          python3 _temp/semantic_selector.py

      - name: Improve article quality with textlint
        run: |
          echo "üìù Improving article quality with textlint..."
          
          # Run textlint on all generated articles
          for article in _posts/*.md; do
            if [ -f "$article" ]; then
              echo "üîç Checking: $(basename "$article")"
              textlint "$article" || true
              
              # Fix common textlint issues
              sed -i 's/„ÄÅ„ÄÅ/„ÄÅ/g' "$article"
              sed -i 's/„ÄÇ„ÄÇ/„ÄÇ/g' "$article"
              
              echo "‚úÖ Improved: $(basename "$article")"
            fi
          done

      - name: Generate images for articles
        env:
          HUGGINGFACE_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
          GEMINI_API_KEY2: ${{ secrets.GEMINI_API_KEY2 }}
        run: |
          export HUGGINGFACE_TOKEN="$HUGGINGFACE_TOKEN"
          
          echo "üé® Generating images for published articles..."
          # Install required dependencies
          pip install requests pillow
          
          # 1. Generate featured images for articles
          python3 scripts/image_generator.py
          
          # 2. Generate Mermaid diagrams for article content
          python3 scripts/mermaid_diagram_generator.py

      - name: Setup Ruby and Jekyll
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: '3.1'
          bundler-cache: true

      - name: Build and Deploy
        run: |
          bundle install
          bundle exec jekyll build

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: './_site'

      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4

      - name: Commit generated articles
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          if [ -n "$(git status --porcelain _posts/)" ]; then
            ARTICLE_COUNT=$(ls _posts/$(date +%Y-%m-%d)-*.md 2>/dev/null | wc -l)
            git add _posts/
            git commit -m "ü§ñ Add $ARTICLE_COUNT unique AI articles - $(date +%Y-%m-%d)"
            git push
            echo "‚úÖ Committed $ARTICLE_COUNT new articles"
          else
            echo "‚ÑπÔ∏è  No new articles to commit"
          fi