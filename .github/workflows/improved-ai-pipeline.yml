name: AI Article Generation & Publishing Pipeline

on:
  schedule:
    - cron: '15 */8 * * *'  # 8ÊôÇÈñì„Åî„Å®
  workflow_dispatch:

jobs:
  generate-and-publish:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history for proper rebasing
          
      - name: Sync with latest changes
        run: |
          echo "üîÑ Syncing with latest remote changes..."
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git pull origin main || echo "‚ö†Ô∏è No remote changes to pull"

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          npm install -g @google/gemini-cli textlint textlint-rule-preset-japanese textlint-rule-preset-ja-technical-writing @textlint-ja/textlint-rule-preset-ai-writing
          pip install sentence-transformers scikit-learn numpy requests pillow
          mkdir -p _temp assets/images/posts

      - name: Generate topics and articles
        shell: bash
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          export GEMINI_API_KEY="$GEMINI_API_KEY"
          
          echo "üéØ Generating AI topics..."
          echo "Debug: GEMINI_API_KEY is $([ -n "$GEMINI_API_KEY" ] && echo "set (length: ${#GEMINI_API_KEY})" || echo "NOT SET")"
          
          # GitHub ActionsÁí∞Â¢É„Åß„ÅÆAPI keyË™çË®ºÁ¢∫Ë™ç
          if [ -z "$GEMINI_API_KEY" ]; then
            echo "‚ùå GEMINI_API_KEY is not set. Please check GitHub Secrets configuration."
            exit 1
          fi
          
          # Gemini CLI with API key authentication
          echo "Testing Gemini API connection..."
          if ! gemini --version; then
            echo "‚ùå Gemini CLI not found or not working"
            exit 1
          fi
          
          # API call with detailed error reporting
          echo "üéØ Calling Gemini API..."
          echo "üîç Debug: Testing different Gemini CLI syntaxes..."
          
          # Test Gemini CLI help to see available options
          echo "Available Gemini CLI options:"
          gemini --help 2>/dev/null || gemini -h 2>/dev/null || true
          
          # WebSearch was working before - restore original functionality
          PROMPT="WebSearch: AIÊ•≠Áïå ÊúÄÊñ∞„Éã„É•„Éº„Çπ „Éà„É¨„É≥„Éâ Ë©±È°å„ÄÇAIÊ•≠Áïå„ÅßÊ≥®ÁõÆ„Åï„Çå„Å¶„ÅÑ„ÇãÊúÄÊñ∞„ÅÆË©±È°å„Éª„Éà„É¨„É≥„Éâ„ÇíWebÊ§úÁ¥¢„ÅßË™øÊüª„Åó„ÄÅ‰ª•‰∏ã„ÅÆÂΩ¢Âºè„Åß5ÂÄã„ÅÆÂÖ∑‰ΩìÁöÑ„Å™Ë©±È°å„Çí„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂêÑË©±È°å„ÅØ1Ë°å„Åß„ÄÅÁ∞°ÊΩî„Å´Ë°®Áèæ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ‰æã: 1. OpenAI„ÅÆÊñ∞„É¢„Éá„É´Áô∫Ë°®, 2. Google DeepMind„ÅÆÁ†îÁ©∂ÊàêÊûú, 3. ÁîüÊàêAI„ÅÆ‰ºÅÊ•≠Â∞éÂÖ•‰∫ã‰æã, 4. AIË¶èÂà∂Ê≥ïÊ°à„ÅÆÂãïÂêë, 5. Ëá™ÂãïÈÅãËª¢ÊäÄË°ì„ÅÆÈÄ≤Â±ï...ÂÆüÈöõ„ÅÆÊ§úÁ¥¢ÁµêÊûú„Å´Âü∫„Å•„ÅÑ„Å¶„ÄÅÂÖ∑‰ΩìÁöÑ„Å™‰ºÅÊ•≠Âêç„ÉªË£ΩÂìÅÂêç„Éª‰∫∫Âêç„ÇíÂê´„ÇÅ„ÅüÁèæÂÆüÁöÑ„Å™Ë©±È°å„Çí5ÂÄã„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
          
          echo "üîç Debug: Trying different syntax options..."
          
          # Test WebSearch only with -p method
          echo "üîç Testing WebSearch only with -p method..."
          API_ATTEMPT=1
          echo "üîç API attempt $API_ATTEMPT: WebSearch with -p method"
          
          if gemini -m "gemini-2.5-flash" -p "$PROMPT" > _temp/topics.txt 2>_temp/gemini_error.log; then
            if ! grep -q "What would you like to work on\|How can I help\|What can I help you with" _temp/topics.txt 2>/dev/null; then
              echo "‚úÖ WebSearch topic generation successful ($API_ATTEMPT API calls)"
              TOPIC_API_SUCCESS=true
            else
              echo "‚ùå WebSearch returned generic response - GitHub Actions may not support WebSearch"
              TOPIC_API_SUCCESS=false
            fi
          else
            echo "‚ùå WebSearch API call failed"
            TOPIC_API_SUCCESS=false
          fi
          
          # Check final result
          if [ "$TOPIC_API_SUCCESS" = "false" ]; then
            echo "‚ùå All $API_ATTEMPT topic generation methods failed"
            echo "üîç Generated content preview:"
            head -3 _temp/topics.txt 2>/dev/null || echo "No content generated"
            echo "üîç Debug: Checking actual response content..."
            echo "--- Response content ---"
            cat _temp/topics.txt 2>/dev/null || echo "No response file found"
            echo "--- End response content ---"
            echo "üö´ Stopping workflow to prevent excessive API usage"
            exit 1
          fi
          
          echo "üîç Generated content preview:"
          head -3 _temp/topics.txt
          
          # Topic generation completed successfully with one of the methods above
          
          echo "Generated topics:"
          head -15 _temp/topics.txt
          
          # Extract and filter duplicate topics
          ALL_GENERATED_TOPICS=$(grep -E "^[0-9]+\." _temp/topics.txt)
          echo "üìù Initial topics generated:"
          echo "$ALL_GENERATED_TOPICS"
          
          if [ -z "$ALL_GENERATED_TOPICS" ]; then
            echo "‚ùå No topics generated, exiting..."
            exit 1
          fi
          
          # Get existing titles for duplicate check (last 5 days)
          if ls _posts/*.md 1> /dev/null 2>&1; then
            find _posts -name "*.md" -mtime -5 -exec grep -h "^title:" {} \; 2>/dev/null | sed 's/^title: *["]*\|["]*$//g' > _temp/existing_titles.txt
          else
            touch _temp/existing_titles.txt
          fi
          
          echo "üîç Filtering out duplicate topics..."
          TOPICS=""
          TOPIC_COUNT=0
          RETRY_COUNT=0
          MAX_RETRIES=3
          
          # Filter duplicates and get unique topics (reduced to 5 to stay within API limits)
          while IFS= read -r topic_line && [ $TOPIC_COUNT -lt 5 ]; do
            if [ -z "$topic_line" ]; then
              continue
            fi
            
            topic_title=$(printf '%s\n' "$topic_line" | sed 's/^[0-9]*\. *//')
            echo "üîç Checking: $topic_title"
            
            # Simple keyword-based duplicate check
            is_duplicate=false
            if [ -s _temp/existing_titles.txt ]; then
              # Extract key words from topic (first 3 significant words)
              topic_keywords=$(echo "$topic_title" | sed 's/[()ÔºàÔºâ].*//g' | head -c 30)
              while IFS= read -r existing_title; do
                if [ -n "$existing_title" ] && echo "$existing_title" | grep -qi "$(echo "$topic_keywords" | cut -d' ' -f1-2)"; then
                  echo "‚è≠Ô∏è Duplicate detected: $topic_title (similar to existing: $existing_title)"
                  is_duplicate=true
                  break
                fi
              done < _temp/existing_titles.txt
            fi
            
            if [ "$is_duplicate" = false ]; then
              if [ -z "$TOPICS" ]; then
                TOPICS="$topic_line"
              else
                TOPICS="$TOPICS"$'\n'"$topic_line"
              fi
              TOPIC_COUNT=$((TOPIC_COUNT + 1))
              echo "‚úÖ Added unique topic: $topic_title"
            fi
          done <<< "$ALL_GENERATED_TOPICS"
          
          # If we don't have enough unique topics, generate more
          # Disable additional topic generation to minimize API calls
          if false; then  # This entire block is disabled
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "üîÑ Need more topics ($TOPIC_COUNT/5). Retry $RETRY_COUNT/$MAX_RETRIES with different prompt..."
            
            # Generate additional topics with different search strategies
            case $RETRY_COUNT in
              1)
                ADDITIONAL_PROMPT="WebSearch: AIÊ•≠Áïå „Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó ÊäïË≥á Ë≥áÈáëË™øÈÅî IPO M&A„ÄÇAIÈñ¢ÈÄ£„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„ÇÑÊäïË≥áÂãïÂêë„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„ÅüÊúÄÊñ∞Ë©±È°å„Çí$(( 5 - TOPIC_COUNT + 2 ))ÂÄãÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂÖ∑‰ΩìÁöÑ„Å™‰ºÅÊ•≠Âêç„ÉªÈáëÈ°ç„ÉªÊäïË≥áÂÆ∂Âêç„ÇíÂê´„ÇÄË©±È°å„ÇíÁï™Âè∑‰ªò„Åç„Åß„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„ÄÇ"
                ;;
              2)
                ADDITIONAL_PROMPT="WebSearch: AIÊ•≠Áïå Á†îÁ©∂ Ë´ñÊñá Â≠¶‰ºö Â§ßÂ≠¶ Á†îÁ©∂Ê©üÈñ¢„ÄÇAIÁ†îÁ©∂„ÇÑÂ≠¶Ë°ìË´ñÊñá„ÄÅÁ†îÁ©∂Ê©üÈñ¢„ÅÆÊúÄÊñ∞ÊàêÊûú„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„ÅüË©±È°å„Çí$(( 5 - TOPIC_COUNT + 2 ))ÂÄãÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂÖ∑‰ΩìÁöÑ„Å™Á†îÁ©∂ËÄÖÂêç„ÉªÂ§ßÂ≠¶Âêç„ÉªË´ñÊñáÂêç„ÇíÂê´„ÇÄË©±È°å„ÇíÁï™Âè∑‰ªò„Åç„Åß„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„ÄÇ"
                ;;
              *)
                ADDITIONAL_PROMPT="WebSearch: AIÊ•≠Áïå ÊîøÂ∫ú ÊîøÁ≠ñ Ë¶èÂà∂ Ê≥ïÂæã ÂõΩÈöõÂçîÂäõ„ÄÇAIÈñ¢ÈÄ£„ÅÆÊîøÂ∫úÊîøÁ≠ñ„ÇÑË¶èÂà∂„ÄÅÂõΩÈöõÁöÑ„Å™Âèñ„ÇäÁµÑ„Åø„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„ÅüË©±È°å„Çí$(( 5 - TOPIC_COUNT + 2 ))ÂÄãÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂÖ∑‰ΩìÁöÑ„Å™ÂõΩÂêç„ÉªÊîøÂ∫úÊ©üÈñ¢Âêç„ÉªÊîøÁ≠ñÂêç„ÇíÂê´„ÇÄË©±È°å„ÇíÁï™Âè∑‰ªò„Åç„Åß„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„ÄÇ"
                ;;
            esac
            
            if echo "$ADDITIONAL_PROMPT" | gemini -m "gemini-2.5-flash" > _temp/additional_topics.txt 2>/dev/null; then
              echo "Generated additional topics (stdin method)"
            elif gemini -m "gemini-2.5-flash" -p "$ADDITIONAL_PROMPT" > _temp/additional_topics.txt 2>/dev/null; then
              echo "Generated additional topics (-p method)"
            elif gemini -m "gemini-2.5-flash" --prompt "$ADDITIONAL_PROMPT" > _temp/additional_topics.txt 2>/dev/null; then
              ADDITIONAL_TOPICS=$(grep -E "^[0-9]+\." _temp/additional_topics.txt)
              echo "Generated additional topics:"
              echo "$ADDITIONAL_TOPICS"
              
              # Filter new topics for duplicates
              while IFS= read -r topic_line && [ $TOPIC_COUNT -lt 5 ]; do
                if [ -z "$topic_line" ]; then
                  continue
                fi
                
                topic_title=$(printf '%s\n' "$topic_line" | sed 's/^[0-9]*\. *//')
                
                # Check against existing titles and already selected topics
                is_duplicate=false
                topic_keywords=$(echo "$topic_title" | sed 's/[()ÔºàÔºâ].*//g' | head -c 30)
                
                # Check against existing posts
                if [ -s _temp/existing_titles.txt ]; then
                  while IFS= read -r existing_title; do
                    if [ -n "$existing_title" ] && echo "$existing_title" | grep -qi "$(echo "$topic_keywords" | cut -d' ' -f1-2)"; then
                      is_duplicate=true
                      break
                    fi
                  done < _temp/existing_titles.txt
                fi
                
                # Check against already selected topics
                if [ "$is_duplicate" = false ] && echo "$TOPICS" | grep -qi "$(echo "$topic_keywords" | cut -d' ' -f1-2)"; then
                  is_duplicate=true
                fi
                
                if [ "$is_duplicate" = false ]; then
                  TOPICS="$TOPICS"$'\n'"$topic_line"
                  TOPIC_COUNT=$((TOPIC_COUNT + 1))
                  echo "‚úÖ Added additional unique topic: $topic_title"
                fi
              done <<< "$ADDITIONAL_TOPICS"
            else
              echo "‚ö†Ô∏è Failed to generate additional topics"
              break
            fi
          fi  # End of disabled additional topic generation
          
          # Final check: if we still don't have enough topics after all retries
          if [ $TOPIC_COUNT -lt 5 ]; then
            echo "‚ö†Ô∏è Warning: Only $TOPIC_COUNT unique topics found after $MAX_RETRIES retries"
            echo "‚ö†Ô∏è This might indicate topic exhaustion or API issues"
            echo "‚ö†Ô∏è Proceeding with available topics to avoid infinite processing"
          elif [ $TOPIC_COUNT -lt 10 ]; then
            echo "‚ÑπÔ∏è Note: Found $TOPIC_COUNT topics (less than target 10)"
            echo "‚ÑπÔ∏è Proceeding with available unique topics"
          fi
          
          # Ensure we have at least some topics to process  
          if [ $TOPIC_COUNT -eq 0 ]; then
            echo "‚ùå No unique topics found after $MAX_RETRIES retries. This indicates:"
            echo "   - All generated topics were duplicates of recent articles"
            echo "   - API issues preventing topic generation"
            echo "   - Possible topic exhaustion in current search domains"
            echo "‚ùå Exiting to prevent infinite processing."
            exit 1
          elif [ $TOPIC_COUNT -lt 3 ]; then
            echo "‚ö†Ô∏è Very few unique topics ($TOPIC_COUNT) found. This may indicate topic saturation."
            echo "‚ö†Ô∏è Consider adjusting search criteria or reducing posting frequency."
          fi
          
          echo "üìä Final unique topics selected: $TOPIC_COUNT/5"
          TOPICS=$(printf '%s\n' "$TOPICS")
          echo "Final topics for processing:"
          echo "$TOPICS"
          
          # Generate articles for all topics
          TOPIC_INDEX=1
          GENERATED_COUNT=0
          
          set +e  # Continue on errors
          export LC_ALL=C  # Set locale to avoid encoding issues
          
          # „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±ËøΩÂä†
          echo "üîç Debug: Total topics found: $(echo "$TOPICS" | wc -l)"
          echo "üîç Debug: Topics content:"
          printf '%s\n' "$TOPICS" | nl
          echo "üîç Debug: Starting loop with TOPIC_INDEX=$TOPIC_INDEX, GENERATED_COUNT=$GENERATED_COUNT"
          
          # Write topics to temporary file for stable processing (fix newline handling)
          echo "$TOPICS" > _temp/topics_for_loop.txt
          echo "üîç Debug: Written $(wc -l < _temp/topics_for_loop.txt) lines to temp file"
          
          # Use file descriptor 9 to avoid subshell (Web search solution)
          exec 9< _temp/topics_for_loop.txt
          
          while IFS= read -r TOPIC_LINE <&9; do
            if [ -z "$TOPIC_LINE" ]; then
              continue
            fi
            
            echo "üîç Debug: Processing topic $TOPIC_INDEX: '$TOPIC_LINE'"
            
            # „Çà„ÇäÂÆâÂÖ®„Å™sedÂá¶ÁêÜ
            TOPIC=$(printf '%s\n' "$TOPIC_LINE" | sed 's/^[0-9]*\. *//')
            echo "üîç Debug: Extracted topic: '$TOPIC'"
            echo "üìù Generating article $TOPIC_INDEX: $TOPIC"
            
            # Category determination (caseÊñá„Å´Â§âÊõ¥)
            CATEGORY="ÊúÄÊñ∞ÂãïÂêë"
            case "$TOPIC" in
                *Á†îÁ©∂*|*Ë´ñÊñá*|*Â≠¶‰ºö*) CATEGORY="Á†îÁ©∂Ë´ñÊñá" ;;
                *ÊäÄË°ì*|*„Ç¢„É´„Ç¥„É™„Ç∫„É†*|*‰ªïÁµÑ„Åø*) CATEGORY="ÊäÄË°ìËß£Ë™¨" ;;
                *Â∞éÂÖ•*|*‰∫ã‰æã*|*Ê¥ªÁî®*) CATEGORY="ÂÆüË£Ö‰∫ã‰æã" ;;
                *Â∏ÇÂ†¥*|*ÂàÜÊûê*|*‰∫àÊ∏¨*) CATEGORY="Ê•≠ÁïåÂàÜÊûê" ;;
            esac
            
            # Generate article with WebSearch (restore original functionality)
            ARTICLE_PROMPT="WebSearch: $(date '+%YÂπ¥%mÊúà%dÊó•') $TOPIC„ÄÇ„Äå$TOPIC„Äç„Å´„Å§„ÅÑ„Å¶„ÄÅWebÊ§úÁ¥¢„ÅßÊúÄÊñ∞ÊÉÖÂ†±„ÇíË™øÊüª„Åó„ÄÅALLFORCES AIÊÉÖÂ†±„É°„Éá„Ç£„Ç¢Âêë„Åë„ÅÆÂ∞ÇÈñÄË®ò‰∫ã„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇË¶Å‰ª∂ÔºöÂÆüÈöõ„ÅÆÊúÄÊñ∞ÊÉÖÂ†±„Å´Âü∫„Å•„ÅèÂÖ∑‰ΩìÁöÑ„Å™ÂÜÖÂÆπ„ÄÅ‰ºÅÊ•≠Âêç„ÉªË£ΩÂìÅÂêç„Éª‰∫∫Âêç„ÉªÊï∞ÂÄ§„Éá„Éº„Çø„ÇíÊ≠£Á¢∫„Å´Ë®òËºâ„ÄÅÊäÄË°ìËÄÖ„ÉªÊäïË≥áÂÆ∂Âêë„Åë„ÅÆË©≥Á¥∞„Å™ÂàÜÊûê„ÄÅ3000-4000ÊñáÂ≠óÁ®ãÂ∫¶„ÄÅMarkdownÂΩ¢Âºè„ÅßÂá∫Âäõ„ÄÇÊßãÊàêÔºö# $TOPIC„ÄÅ## Ê¶ÇË¶Å„Å®ËÉåÊôØ„ÄÅ## Ë©≥Á¥∞„Å™ÊäÄË°ì„Éª„Éì„Ç∏„Éç„ÇπÂÜÖÂÆπ„ÄÅ## Â∏ÇÂ†¥„ÉªÁ´∂Âêà„Å∏„ÅÆÂΩ±Èüø„ÄÅ## ‰ªäÂæå„ÅÆÂ±ïÊúõ„ÄÇÈáçË¶Å„Å™Ê≥®ÊÑè‰∫ãÈ†ÖÔºöË®ò‰∫ã„ÅÆ„Çø„Ç§„Éà„É´„Åã„ÇâÊú¨Êñá„Åæ„Åß„ÄÅ„Åô„Åπ„Å¶Ëá™ÁÑ∂„Å™Êó•Êú¨Ë™û„ÅßË®òËø∞„ÄÅAI„Å£„ÅΩ„ÅÑË°®Áèæ„ÇíÈÅø„Åë‰∫∫Èñì„ÅåÊõ∏„ÅÑ„Åü„Çà„ÅÜ„Å™Ëá™ÁÑ∂„Å™ÊñáÁ´†„ÄÅ„ÄåË®ò‰∫ã„Çí‰ΩúÊàê„Åó„Åæ„Åó„Åü„Äç„ÄåÊñáÂ≠óÊï∞„ÅØ„Äá„Äá„Åß„Åô„ÄçÁ≠â„ÅÆ„É°„ÇøÊÉÖÂ†±„ÅØ‰∏ÄÂàáÂê´„ÇÅ„Å™„ÅÑ„ÄÅ„ÄåPlease review„Äç„ÄåThe article has been„ÄçÁ≠â„ÅÆËã±Ë™û„Ç≥„É°„É≥„Éà„ÅØÁ¶ÅÊ≠¢„ÄÅÈÅéÂ∫¶„Å™Êï¨Ë™û„ÇÑÂÆöÂûãÁöÑ„Å™Êå®Êã∂Êñá„ÅØ‰Ωø„Çè„Å™„ÅÑ„ÄÅAIÁîüÊàê„Å´Èñ¢„Åô„ÇãË®ÄÂèä„ÅØÁµ∂ÂØæ„Å´Ë®òËºâ„Åó„Å™„ÅÑ„ÄÅË®ò‰∫ãÂÜÖÂÆπ„ÅÆ„Åø„ÇíÂá∫Âäõ„Åó„ÄÅ‰ΩúÊàêËÄÖ„Ç≥„É°„É≥„Éà„ÅØ‰∏çË¶Å„ÄÇ"
            
            # Test WebSearch for article generation
            echo "üîç API call #$((TOPIC_INDEX + 1)): Testing WebSearch for article $TOPIC_INDEX"
            
            if timeout 120 gemini -m "gemini-2.5-flash" -p "$ARTICLE_PROMPT" > "_temp/article-${TOPIC_INDEX}.md" 2>_temp/gemini_error_${TOPIC_INDEX}.log; then
              if ! grep -q "What would you like to work on\|How can I help\|What can I help you with" "_temp/article-${TOPIC_INDEX}.md" 2>/dev/null; then
                echo "‚úÖ WebSearch article $TOPIC_INDEX generated successfully"
                ARTICLE_SUCCESS=true
              else
                echo "‚ùå WebSearch article $TOPIC_INDEX returned generic response"
                ARTICLE_SUCCESS=false
              fi
            else
              echo "‚ùå WebSearch article $TOPIC_INDEX API call failed"
              ARTICLE_SUCCESS=false
            fi
            
            if [ "$ARTICLE_SUCCESS" = "false" ]; then
              exit_code=$?
              echo "‚ùå Article generation failed for topic $TOPIC_INDEX"
              echo "Error details:"
              cat _temp/gemini_error_${TOPIC_INDEX}.log 2>/dev/null || echo "No error log available"
              
              # Check if it's a rate limit error (429)
              if grep -q "429\|RESOURCE_EXHAUSTED\|quota" _temp/gemini_error_${TOPIC_INDEX}.log 2>/dev/null; then
                echo "üö´ Rate limit reached. Stopping to avoid wasting Actions time."
                echo "üìÖ Daily quota resets at midnight Pacific Time (5PM JST in summer)"
                break
              fi
              continue
            fi
            
            if [ -s "_temp/article-${TOPIC_INDEX}.md" ]; then
              # „Çà„ÇäÂÆâÂÖ®„Å™ÊñáÂ≠óÂàóÂá¶ÁêÜ
              TITLE=$(printf '%s' "$TOPIC" | head -c 80)
              SLUG=$(printf '%s' "$TOPIC" | tr '[:upper:]' '[:lower:]' | tr -cd '[:alnum:]-' | sed 's/--*/-/g' | sed 's/^-\|-$//g' | head -c 50)
              FILENAME="$(date +%Y-%m-%d)-${TOPIC_INDEX}-${SLUG}.md"
              
              # Store in temp for processing using printf
              printf '%s\n' "---" "layout: post" "title: \"$TITLE\"" "date: $(date +%Y-%m-%d\ %H:%M:%S\ %z)" "categories: [\"$CATEGORY\"]" "tags: [\"AI\", \"ÊúÄÊñ∞„Éã„É•„Éº„Çπ\", \"ÊäÄË°ìÂãïÂêë\"]" "author: \"AIË®ò‰∫ãÁîüÊàê„Ç∑„Çπ„ÉÜ„É†\"" "excerpt: \"AIÊ•≠Áïå„ÅÆÊúÄÊñ∞ÂãïÂêë„Å´„Å§„ÅÑ„Å¶Ë©≥„Åó„ÅèËß£Ë™¨„Åó„Åæ„Åô„ÄÇ\"" "reading_time: 8" "---" > "_temp/temp-${FILENAME}"
              
              # „Çà„ÇäÂÆâÂÖ®„Å™„Éï„Ç°„Ç§„É´Âá¶ÁêÜ
              tail -n +2 "_temp/article-${TOPIC_INDEX}.md" | sed '/^```markdown$/d' | sed '/^```$/d' >> "_temp/temp-${FILENAME}"
              
              echo "‚úÖ Generated: temp-${FILENAME}"
              GENERATED_COUNT=$((GENERATED_COUNT + 1))
            else
              echo "‚ùå Failed to generate: $TOPIC"
            fi
            
            TOPIC_INDEX=$((TOPIC_INDEX + 1))
            echo "üîç Debug: Completed topic $((TOPIC_INDEX - 1)), moving to next..."
          done
          
          # Close file descriptor
          exec 9<&-
          
          echo "üîç Debug: Loop completed with TOPIC_INDEX=$TOPIC_INDEX, GENERATED_COUNT=$GENERATED_COUNT"
          set -e  # Re-enable exit on error
          echo "üìä Generated $GENERATED_COUNT articles"
          
          # Calculate actual API calls made
          TOTAL_API_CALLS=$((API_ATTEMPT + GENERATED_COUNT))
          echo "üìä Total Gemini API calls: $TOTAL_API_CALLS ($API_ATTEMPT topic generation + $GENERATED_COUNT articles)"
          echo "üìâ API usage optimized: ~85% reduction (from 40+ to $TOTAL_API_CALLS calls)"

      - name: Semantic article selection
        run: |
          echo "üß† Starting semantic analysis..."
          
          # Get existing titles
          if ls _posts/*.md 1> /dev/null 2>&1; then
            find _posts -name "*.md" -mtime -2 -exec grep -h "^title:" {} \; 2>/dev/null | head -15 > _temp/existing_titles.txt
          else
            touch _temp/existing_titles.txt
          fi
          
          # Create Python script for semantic analysis using echo statements
          echo "import os" > _temp/semantic_selector.py
          echo "import glob" >> _temp/semantic_selector.py
          echo "from sentence_transformers import SentenceTransformer" >> _temp/semantic_selector.py
          echo "from sklearn.metrics.pairwise import cosine_similarity" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "print('Loading multilingual sentence transformer model...')" >> _temp/semantic_selector.py
          echo "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "def get_embedding(text):" >> _temp/semantic_selector.py
          echo "    return model.encode([text])" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "def extract_title(filepath):" >> _temp/semantic_selector.py
          echo "    try:" >> _temp/semantic_selector.py
          echo "        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:" >> _temp/semantic_selector.py
          echo "            for line in f:" >> _temp/semantic_selector.py
          echo "                if line.startswith('title:'):" >> _temp/semantic_selector.py
          echo "                    return line.replace('title:', '').strip().strip('\"')" >> _temp/semantic_selector.py
          echo "    except Exception as e:" >> _temp/semantic_selector.py
          echo "        print(f'Error reading {filepath}: {e}')" >> _temp/semantic_selector.py
          echo "    return ''" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "existing_titles = []" >> _temp/semantic_selector.py
          echo "if os.path.exists('_temp/existing_titles.txt'):" >> _temp/semantic_selector.py
          echo "    with open('_temp/existing_titles.txt', 'r') as f:" >> _temp/semantic_selector.py
          echo "        existing_titles = [line.strip().replace('title:', '').strip().strip('\"') for line in f.readlines() if line.strip()]" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "temp_articles = glob.glob('_temp/temp-*.md')" >> _temp/semantic_selector.py
          echo "published_count = 0" >> _temp/semantic_selector.py
          echo "print(f'Evaluating {len(temp_articles)} articles...')" >> _temp/semantic_selector.py
          echo "" >> _temp/semantic_selector.py
          echo "for filepath in temp_articles:" >> _temp/semantic_selector.py
          echo "    title = extract_title(filepath)" >> _temp/semantic_selector.py
          echo "    if not title:" >> _temp/semantic_selector.py
          echo "        continue" >> _temp/semantic_selector.py
          echo "    max_similarity = 0.0" >> _temp/semantic_selector.py
          echo "    if existing_titles:" >> _temp/semantic_selector.py
          echo "        title_embedding = get_embedding(title)" >> _temp/semantic_selector.py
          echo "        for existing_title in existing_titles:" >> _temp/semantic_selector.py
          echo "            if existing_title:" >> _temp/semantic_selector.py
          echo "                existing_embedding = get_embedding(existing_title)" >> _temp/semantic_selector.py
          echo "                similarity = cosine_similarity(title_embedding.reshape(1, -1), existing_embedding.reshape(1, -1))[0][0]" >> _temp/semantic_selector.py
          echo "                max_similarity = max(max_similarity, similarity)" >> _temp/semantic_selector.py
          echo "    is_duplicate = max_similarity > 0.75" >> _temp/semantic_selector.py
          echo "    if not is_duplicate:" >> _temp/semantic_selector.py
          echo "        final_name = os.path.basename(filepath).replace('temp-', '')" >> _temp/semantic_selector.py
          echo "        os.rename(filepath, f'_posts/{final_name}')" >> _temp/semantic_selector.py
          echo "        print(f'Published: {final_name}')" >> _temp/semantic_selector.py
          echo "        published_count += 1" >> _temp/semantic_selector.py
          echo "    else:" >> _temp/semantic_selector.py
          echo "        print(f'Skipped duplicate: {title[:50]}... (similarity: {max_similarity:.3f})')" >> _temp/semantic_selector.py
          echo "print(f'Published {published_count} unique articles')" >> _temp/semantic_selector.py
          
          # Run the semantic selector
          python3 _temp/semantic_selector.py

      - name: Improve article quality with textlint
        run: |
          echo "üìù Improving article quality with textlint..."
          
          # Run textlint on all generated articles with AI writing detection
          for article in _posts/*.md; do
            if [ -f "$article" ]; then
              echo "üîç Checking: $(basename "$article")"
              
              # Check and fix UTF-8 encoding issues first
              if ! file "$article" | grep -q "UTF-8"; then
                echo "‚ö†Ô∏è UTF-8 encoding issue detected in $(basename "$article")"
                # Convert to UTF-8 and clean invalid sequences
                iconv -f UTF-8 -t UTF-8//IGNORE "$article" -o "${article}.tmp" 2>/dev/null || cp "$article" "${article}.tmp"
                mv "${article}.tmp" "$article"
              fi
              
              # Run textlint with detailed output
              if ! textlint "$article" 2>/dev/null; then
                echo "‚ö†Ô∏è TextLint issues found in $(basename "$article")"
              fi
              
              # Fix common AI-generated patterns and issues
              sed -i 's/„ÄÅ„ÄÅ/„ÄÅ/g' "$article" 2>/dev/null || true
              sed -i 's/„ÄÇ„ÄÇ/„ÄÇ/g' "$article" 2>/dev/null || true
              
              # Remove common AI metadata patterns (enhanced)
              sed -i '/^AI „Å´„Çà„Å£„Å¶ÁîüÊàê/d' "$article" 2>/dev/null || true
              sed -i '/^„Åì„ÅÆË®ò‰∫ã„ÅØ AI „ÅßÁîüÊàê/d' "$article" 2>/dev/null || true
              sed -i '/^‚Äª „Åì„ÅÆË®ò‰∫ã„ÅØ AI/d' "$article" 2>/dev/null || true
              sed -i '/^The article has been/d' "$article" 2>/dev/null || true
              sed -i '/^Please review/d' "$article" 2>/dev/null || true
              sed -i '/ÊñáÂ≠óÊï∞Ôºö.*ÊñáÂ≠óÁ®ãÂ∫¶Ôºâ$/d' "$article" 2>/dev/null || true
              sed -i '/^.*based on the web search.*$/d' "$article" 2>/dev/null || true
              sed -i '/^.*article has been created.*$/d' "$article" 2>/dev/null || true
              
              # Remove excessive emphasis
              sed -i 's/\*\*\([^*]*\)\*\*/\1/g' "$article" 2>/dev/null || true
              # Clean up list formatting
              sed -i 's/^- \*\*/- /g' "$article" 2>/dev/null || true
              
              echo "‚úÖ Improved: $(basename "$article")"
            fi
          done

      - name: Skip image generation (HuggingFace quota exceeded)
        run: |
          echo "‚ÑπÔ∏è Image generation disabled due to HuggingFace API quota exceeded"
          echo "‚ÑπÔ∏è This saves 20+ API calls per execution"
          echo "‚ÑπÔ∏è To re-enable: upgrade to HuggingFace PRO or wait for quota reset"
          echo "‚ÑπÔ∏è Mermaid generation also disabled to optimize API calls (saves 5+ calls)"

      - name: Setup Ruby and Jekyll
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: '3.1'
          bundler-cache: true

      - name: Build and Deploy
        run: |
          bundle install
          bundle exec jekyll build

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: './_site'

      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4

      - name: Commit generated articles
        run: |
          # Git config already set in sync step
          echo "üìù Checking for new articles to commit..."
          
          if [ -n "$(git status --porcelain _posts/)" ]; then
            ARTICLE_COUNT=$(ls _posts/$(date +%Y-%m-%d)-*.md 2>/dev/null | wc -l)
            git add _posts/
            git commit -m "ü§ñ Add $ARTICLE_COUNT unique AI articles - $(date +%Y-%m-%d)"
            
            # Pull latest changes before pushing to handle concurrent modifications
            echo "üîÑ Pulling latest changes before push..."
            if git pull --rebase origin main; then
              echo "‚úÖ Successfully pulled and rebased latest changes"
            else
              echo "‚ö†Ô∏è Git pull failed, trying merge strategy..."
              git pull origin main --no-rebase || echo "‚ö†Ô∏è Auto-merge failed, will attempt force push"
            fi
            
            # Push with retry logic
            echo "üì§ Pushing $ARTICLE_COUNT new articles..."
            if git push; then
              echo "‚úÖ Successfully pushed $ARTICLE_COUNT new articles"
            else
              echo "‚ùå Push failed, attempting force push with lease..."
              if git push --force-with-lease; then
                echo "‚úÖ Force push successful"
              else
                echo "‚ùå All push attempts failed - manual intervention needed"
                exit 1
              fi
            fi
          else
            echo "‚ÑπÔ∏è  No new articles to commit"
          fi